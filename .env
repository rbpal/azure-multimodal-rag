# Azure Multi-Modal RAG Configuration

# LLM Backend ("mock", "ollama", "llama-cpp")
LLM_BACKEND=mock

# Model Configuration
LLAMA_MODEL_PATH=./models/llama-3.1-8b-q6_k.gguf
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Ollama Settings
OLLAMA_MODEL=llama3.1:8b
OLLAMA_URL=http://localhost:11434

# Memory Settings
MAX_MEMORY_GB=32
LLAMA_CONTEXT_SIZE=4096
LLAMA_THREADS=8

# Vector Store
CHROMA_PERSIST_DIR=./data/vector_store

# Processing Settings
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_IMAGES_PER_DOCUMENT=50

# API Settings
API_HOST=127.0.0.1
API_PORT=8000
DEBUG=True

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/application.log
